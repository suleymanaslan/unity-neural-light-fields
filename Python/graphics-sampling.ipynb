{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9adbec-1fa9-4c80-b8b5-a7c73d2401fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shift_factor = 0\n",
    "scale_factor = 1\n",
    "\n",
    "def get_mgrid(sidelen, dim):\n",
    "    if dim == 4:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0], :sidelen[1], :sidelen[2], :sidelen[3]], axis=-1)[None, ...].astype(np.float32)\n",
    "        for i in range(dim):\n",
    "            pixel_coords[..., i] = pixel_coords[..., i] / max(sidelen[i] - 1, 1)\n",
    "        pixel_coords = torch.from_numpy((pixel_coords - 0.5) * 2).view(-1, dim)\n",
    "        pixel_coords = pixel_coords + torch.Tensor([shift_factor, shift_factor, 0, 0])\n",
    "        pixel_coords = pixel_coords * torch.Tensor([scale_factor, scale_factor, 1, 1])\n",
    "        return pixel_coords.view((sidelen[0] * sidelen[1], sidelen[2], sidelen[3], dim))\n",
    "    raise NotImplementedError(f'Not implemented for dim={dim}')\n",
    "\n",
    "class LightFieldData:\n",
    "    def __init__(self, batch_size):\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def load_data_capture(self, data_folder):\n",
    "        u, v = 64, 64\n",
    "        h, w = 256, 256\n",
    "        c = 3\n",
    "        data = torch.zeros((u * v, h, w, c))\n",
    "        for ui in range(u):\n",
    "            for vi in range(v):\n",
    "                im = cv2.imread(f'{data_folder}/{vi:03d}-{ui:03d}.png')\n",
    "                im = cv2.resize(im, (h, w))\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                im = torch.from_numpy(((im * 2.0 / 255.0) - 1.0).astype(np.float32))\n",
    "                data[ui*u+vi] = im\n",
    "        \n",
    "        self.mgrid = get_mgrid((u, v, h, w), dim=4)\n",
    "        self.data = data\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        self.cursor = len(self.indices)\n",
    "        self.height = h\n",
    "        self.width = w\n",
    "        \n",
    "        print(f\"Data:{self.data.shape}, Type:{self.data.dtype}, Range:{(self.data.min(), self.data.max())}\")\n",
    "        print(f\"Mesh Grid:{self.mgrid.shape}, Type:{self.mgrid.dtype}, Range:{(self.mgrid.min(), self.mgrid.max())}\")\n",
    "        \n",
    "    def shuffle(self):\n",
    "        self.indices = np.random.permutation(self.indices)\n",
    "        self.cursor = 0\n",
    "    \n",
    "    def next_batch(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if self.cursor + batch_size > len(self.indices):\n",
    "            self.shuffle()\n",
    "        batch_indices = self.indices[self.cursor:self.cursor + batch_size]\n",
    "        self.cursor += batch_size\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_coord = self.mgrid[batch_indices]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "    \n",
    "    def pixel_batch(self, batch_size):\n",
    "        data_shape = self.data.view(-1, 3).shape\n",
    "        pixel_ix = np.random.choice(data_shape[0], batch_size)\n",
    "        batch_data = self.data.view(-1, 3)[pixel_ix]\n",
    "        batch_coord = self.mgrid.view(-1, 4)[pixel_ix]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "\n",
    "    def tensor_to_plt(self, in_tensor):\n",
    "        plt.imshow(in_tensor[...,0:3].detach().cpu().clamp(-1,1) * 0.5 + 0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a35fe-b81c-41eb-bc02-312221a01cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_data = LightFieldData(batch_size=8)\n",
    "lf_data.load_data_capture('datasets/Ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d925fd-3238-48a5-a551-b9dcf183bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "W_0 = 30\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_hidden_layers, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(nn.Sequential(nn.Linear(in_features, hidden_features), Sine()))\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.net.append(nn.Sequential(nn.Linear(hidden_features, hidden_features), Sine()))\n",
    "            # self.net.append(ResidualBlock(nn.Sequential(nn.Linear(hidden_features, hidden_features), Sine())))\n",
    "        self.net.append(nn.Sequential(nn.Linear(hidden_features, out_features)))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.net.apply(sine_init)\n",
    "        self.net[0].apply(first_layer_sine_init)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "\n",
    "def sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-np.sqrt(6 / num_input) / W_0, np.sqrt(6 / num_input) / W_0)\n",
    "\n",
    "def first_layer_sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def __init(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(W_0 * input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        self.net = FCBlock(in_features, out_features, num_hidden_layers, hidden_features)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = Siren(in_features=4, out_features=3, hidden_features=1024, num_hidden_layers=3)\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"outputs/ship-3-1024-30.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716064e4-6e3f-4625-b969-3dbf4dc4d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "folder_str = \"graphics/sampling-baseline\"\n",
    "files = glob.glob(f'{folder_str}/*.png')\n",
    "\n",
    "def to_uint8(im):\n",
    "    return ((im.detach().cpu().clamp(-1,1).numpy() * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "if not os.path.exists(folder_str):\n",
    "    os.makedirs(folder_str)\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "dpi = 96\n",
    "skip = 6\n",
    "\n",
    "resolution = 120\n",
    "for i in range(resolution):\n",
    "    u = (i-resolution/2) / (resolution/2)\n",
    "    x = math.sin(math.pi * u)\n",
    "    z = math.cos(math.pi * u)\n",
    "    novel_coords = torch.Tensor([x, z]) * scale_factor\n",
    "    \n",
    "    im_coord = lf_data.mgrid[0].clone()\n",
    "    im_coord[:,:,:2] = novel_coords\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im_coord = im_coord.to(device)\n",
    "        model_out = model(im_coord)\n",
    "        model_out = to_uint8(model_out)\n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    xy = im_coord[:,:,2:].cpu().numpy()\n",
    "    x_samples = (xy[::skip,::skip,0].flatten() + 1) * 128\n",
    "    y_samples = (xy[::skip,::skip,1].flatten() + 1) * 128\n",
    "\n",
    "    plt.figure(figsize=(4, 4), dpi=dpi)\n",
    "    plt.imshow(np.flip(model_out, axis=0), origin='lower')\n",
    "    plt.scatter(x_samples, y_samples, s=4, c=\"r\", alpha=1, linewidths=0)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{folder_str}/{i:03d}.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "anim_file = f'{folder_str}.mp4'\n",
    "files = glob.glob(f'{folder_str}/*.png')\n",
    "\n",
    "frames = []\n",
    "filenames = sorted(files)\n",
    "for i, filename in enumerate(filenames):\n",
    "    frames.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave(anim_file, frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7ecd8-b608-4fbf-9371-b41888c2e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import imageio\n",
    "import scipy.ndimage\n",
    "\n",
    "def fnc(x): return np.sign(x.sum())\n",
    "\n",
    "def to_uint8(im):\n",
    "    return ((im.detach().cpu().clamp(-0.85,0.85).numpy() * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "folder_str = \"graphics/sampling-strategy\"\n",
    "files = glob.glob(f'{folder_str}/*.png')\n",
    "\n",
    "if not os.path.exists(folder_str):\n",
    "    os.makedirs(folder_str)\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "dpi = 96\n",
    "skip = 4\n",
    "prev_out = None\n",
    "same_out = None\n",
    "\n",
    "resolution = 120\n",
    "for i in range(resolution):\n",
    "    u = (i-resolution/2) / (resolution/2)\n",
    "    x = math.sin(math.pi * u)\n",
    "    z = math.cos(math.pi * u)\n",
    "    novel_coords = torch.Tensor([x, z]) * scale_factor\n",
    "    \n",
    "    im_coord = lf_data.mgrid[0].clone()\n",
    "    im_coord[:,:,:2] = novel_coords\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im_coord = im_coord.to(device)\n",
    "        model_out = model(im_coord)\n",
    "        model_out = to_uint8(model_out)\n",
    "        if prev_out is not None:\n",
    "            same_out = prev_out != model_out.sum(axis=2)\n",
    "            same_out = scipy.ndimage.generic_filter(same_out, fnc, 5)\n",
    "        prev_out = model_out.sum(axis=2)\n",
    "    \n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    if i != 1:\n",
    "        plt.figure(figsize=(4, 4), dpi=dpi)\n",
    "        plt.imshow(np.flip(model_out, axis=0), origin='lower')\n",
    "        plt.scatter(y_samples, 255-x_samples, s=4, c=\"r\", alpha=1, linewidths=0)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{folder_str}/{i:03d}.png\", bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "    \n",
    "    im_coord = im_coord[::skip,::skip,:]\n",
    "    same_out = same_out[::skip,::skip]\n",
    "    xy = im_coord[:,:,2:].cpu().numpy()\n",
    "    xy = xy[same_out]\n",
    "    x_samples = (xy[:,0] + 1) * 128\n",
    "    y_samples = (xy[:,1] + 1) * 128\n",
    "\n",
    "anim_file = f'{folder_str}.mp4'\n",
    "files = glob.glob(f'{folder_str}/*.png')\n",
    "\n",
    "frames = []\n",
    "filenames = sorted(files)\n",
    "for i, filename in enumerate(filenames):\n",
    "    frames.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave(anim_file, frames, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
