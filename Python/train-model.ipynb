{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1efba7-3c88-4b15-b81d-272716eaa05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shift_factor = 0\n",
    "scale_factor = 1\n",
    "\n",
    "def get_mgrid(sidelen, dim):\n",
    "    if dim == 4:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0], :sidelen[1], :sidelen[2], :sidelen[3]], axis=-1)[None, ...].astype(np.float32)\n",
    "        for i in range(dim):\n",
    "            pixel_coords[..., i] = pixel_coords[..., i] / max(sidelen[i] - 1, 1)\n",
    "        pixel_coords = torch.from_numpy((pixel_coords - 0.5) * 2).view(-1, dim)\n",
    "        pixel_coords = pixel_coords + torch.Tensor([shift_factor, shift_factor, 0, 0])\n",
    "        pixel_coords = pixel_coords * torch.Tensor([scale_factor, scale_factor, 1, 1])\n",
    "        return pixel_coords.view((sidelen[0] * sidelen[1], sidelen[2], sidelen[3], dim))\n",
    "    raise NotImplementedError(f'Not implemented for dim={dim}')\n",
    "\n",
    "class LightFieldData:\n",
    "    def __init__(self, batch_size):\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def load_data_capture(self, data_folder):\n",
    "        u, v = 64, 64\n",
    "        h, w = 256, 256\n",
    "        c = 3\n",
    "        data = torch.zeros((u * v, h, w, c))\n",
    "        for ui in range(u):\n",
    "            for vi in range(v):\n",
    "                im = cv2.imread(f'{data_folder}/{vi:03d}-{ui:03d}.png')\n",
    "                im = cv2.resize(im, (h, w))\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                im = torch.from_numpy(((im * 2.0 / 255.0) - 1.0).astype(np.float32))\n",
    "                data[ui*u+vi] = im\n",
    "        \n",
    "        self.mgrid = get_mgrid((u, v, h, w), dim=4)\n",
    "        self.data = data\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        self.cursor = len(self.indices)\n",
    "        self.height = h\n",
    "        self.width = w\n",
    "        \n",
    "        print(f\"Data:{self.data.shape}, Type:{self.data.dtype}, Range:{(self.data.min(), self.data.max())}\")\n",
    "        print(f\"Mesh Grid:{self.mgrid.shape}, Type:{self.mgrid.dtype}, Range:{(self.mgrid.min(), self.mgrid.max())}\")\n",
    "        \n",
    "    def shuffle(self):\n",
    "        self.indices = np.random.permutation(self.indices)\n",
    "        self.cursor = 0\n",
    "    \n",
    "    def next_batch(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if self.cursor + batch_size > len(self.indices):\n",
    "            self.shuffle()\n",
    "        batch_indices = self.indices[self.cursor:self.cursor + batch_size]\n",
    "        self.cursor += batch_size\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_coord = self.mgrid[batch_indices]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "    \n",
    "    def pixel_batch(self, batch_size):\n",
    "        data_shape = self.data.view(-1, 3).shape\n",
    "        pixel_ix = np.random.choice(data_shape[0], batch_size)\n",
    "        batch_data = self.data.view(-1, 3)[pixel_ix]\n",
    "        batch_coord = self.mgrid.view(-1, 4)[pixel_ix]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "\n",
    "    def tensor_to_plt(self, in_tensor):\n",
    "        plt.imshow(in_tensor[...,0:3].detach().cpu().clamp(-1,1) * 0.5 + 0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed4e67-34d2-4290-b25f-daf2c0ad1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_data = LightFieldData(batch_size=8)\n",
    "# lf_data.load_data_sintel('datasets/', u=3, v=3, channels=3, height=384, width=384, rs=450, bs=1)\n",
    "lf_data.load_data_capture('datasets/Ship-360')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57db010-ab66-4980-bb19-19b61c34d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, all_coord = lf_data.data, lf_data.mgrid\n",
    "for i in range(len(all_data[:2])):\n",
    "    lf_data.tensor_to_plt(all_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef815f-a732-4aa7-8ee9-8a9b2a0719b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "W_0 = 30\n",
    "\n",
    "# class FullyConnected(nn.Module):\n",
    "#     def __init__(self, in_features, out_features, num_hidden_layers, hidden_features):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.net = []\n",
    "#         self.net.append(nn.Sequential(nn.Linear(in_features, hidden_features), nn.ReLU()))\n",
    "#         for i in range(num_hidden_layers):\n",
    "#             self.net.append(nn.Sequential(nn.Linear(hidden_features, hidden_features), nn.ReLU()))\n",
    "#         self.net.append(nn.Sequential(nn.Linear(hidden_features, out_features)))\n",
    "\n",
    "#         self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "#     def forward(self, inputs):\n",
    "#         return self.net(inputs)\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, module):\n",
    "#         super().__init__()\n",
    "#         self.module = module\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         return self.module(inputs) + inputs\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_hidden_layers, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(nn.Sequential(nn.Linear(in_features, hidden_features), Sine()))\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.net.append(nn.Sequential(nn.Linear(hidden_features, hidden_features), Sine()))\n",
    "            # self.net.append(ResidualBlock(nn.Sequential(nn.Linear(hidden_features, hidden_features), Sine())))\n",
    "        self.net.append(nn.Sequential(nn.Linear(hidden_features, out_features)))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.net.apply(sine_init)\n",
    "        self.net[0].apply(first_layer_sine_init)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "\n",
    "def sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-np.sqrt(6 / num_input) / W_0, np.sqrt(6 / num_input) / W_0)\n",
    "\n",
    "def first_layer_sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def __init(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(W_0 * input)\n",
    "        # return torch.sinc(W_0 * input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        self.net = FCBlock(in_features, out_features, num_hidden_layers, hidden_features)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "    \n",
    "class MultiSiren(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, num_hidden_layers, split):\n",
    "        super().__init__()\n",
    "        self.uv_nets = []\n",
    "        self.split = split\n",
    "        for _ in range(self.split):\n",
    "            v_nets = []\n",
    "            for _ in range(self.split):\n",
    "                v_nets.append(FCBlock(in_features, out_features, num_hidden_layers, hidden_features))\n",
    "            self.uv_nets.append(nn.ModuleList(v_nets))\n",
    "        self.uv_nets = nn.ModuleList(self.uv_nets)\n",
    "            \n",
    "    def uv_to_index(self, u, v):\n",
    "        ui = 0\n",
    "        while u > (-1 + 2/self.split):\n",
    "            ui += 1\n",
    "            u -= 2/self.split\n",
    "        vi = 0\n",
    "        while v > (-1 + 2/self.split):\n",
    "            vi += 1\n",
    "            v -= 2/self.split\n",
    "        return (ui, vi)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        u = inputs.flatten()[0].item()\n",
    "        v = inputs.flatten()[1].item()\n",
    "        uv_ix = self.uv_to_index(u, v)\n",
    "        return self.uv_nets[uv_ix[0]][uv_ix[1]](inputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "layers = 3\n",
    "features = 1024\n",
    "# model = Siren(in_features=4, out_features=3, hidden_features=features, num_hidden_layers=layers)\n",
    "model = MultiSiren(in_features=4, out_features=3, hidden_features=features, num_hidden_layers=layers, split=2)\n",
    "# model = FullyConnected(in_features=4, out_features=3, hidden_features=1024, num_hidden_layers=3)\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540b1e9-afee-47b8-9e12-1ae91a7bf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dummy_input = torch.randn(64*64, 4, device=\"cuda\")\n",
    "model_str = f\"ship360-multi-{layers}-{features}-{W_0}\"\n",
    "print(model_str)\n",
    "\n",
    "step = 0\n",
    "while True:\n",
    "    # batch_data, batch_coord = lf_data.pixel_batch(batch_size=100_000)\n",
    "    batch_data, batch_coord = lf_data.next_batch(batch_size=1)\n",
    "    model_output = model(batch_coord)\n",
    "    loss = (model_output - batch_data).abs().mean()\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    step += 1\n",
    "    if step == 1 or step % 50 == 0:\n",
    "        print(f\"{datetime.now()} step:{step:04d}, loss:{loss.item():0.8f}\")\n",
    "        torch.save(model.state_dict(), f\"outputs/{model_str}.pth\")\n",
    "        # torch.onnx.export(model,\n",
    "        #                   dummy_input,\n",
    "        #                   f\"outputs/{model_str}.onnx\",\n",
    "        #                   export_params=True,\n",
    "        #                   opset_version=9,\n",
    "        #                   do_constant_folding=True,\n",
    "        #                   input_names = ['x'],\n",
    "        #                   output_names = ['y']\n",
    "        #                  )\n",
    "    # if step % 150 == 0:\n",
    "    #     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352e92a-f8ad-4624-a996-75ff934d31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_data, batch_coord = lf_data.next_batch(batch_size=1)\n",
    "    model_output = model(batch_coord)\n",
    "for i in range(len(model_output)):\n",
    "    lf_data.tensor_to_plt(batch_data[i])\n",
    "    lf_data.tensor_to_plt(model_output[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
