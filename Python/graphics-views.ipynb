{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78a459-2bfd-410c-ad81-c651a26f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # coord animation\n",
    "# import os\n",
    "# import math\n",
    "# import glob\n",
    "# import cairo\n",
    "# import imageio\n",
    "\n",
    "# files = glob.glob(f'graphics/coord/*.png')\n",
    "# for f in files:\n",
    "#     os.remove(f)\n",
    "\n",
    "# resolution = 60\n",
    "# for i in range(resolution):\n",
    "#     u = (i-resolution/2) / (resolution/2)\n",
    "#     x = (math.cos(math.pi * u) + 1) / 2.0\n",
    "#     z = (math.sin(math.pi * u) + 1) / 2.0\n",
    "#     coord_scale = 0.9\n",
    "#     x = x * coord_scale + 0.5 * (1-coord_scale)\n",
    "#     z = z * coord_scale + 0.5 * (1-coord_scale)\n",
    "    \n",
    "#     pixel_scale = 128\n",
    "#     ims = cairo.ImageSurface(cairo.FORMAT_ARGB32, pixel_scale, pixel_scale)\n",
    "#     cr = cairo.Context(ims)\n",
    "#     cr.scale(pixel_scale, pixel_scale)\n",
    "\n",
    "#     gray_c = 0.3\n",
    "\n",
    "#     cr.set_source_rgb(gray_c, gray_c, gray_c)\n",
    "#     cr.rectangle(0.0, 0.0, 1.0, 1.0)\n",
    "#     cr.fill()\n",
    "\n",
    "    \n",
    "#     size = 0.1\n",
    "#     cr.set_source_rgb(1.0, 0.0, 0.0)\n",
    "#     cr.rectangle(x - size/2, z - size/2, size, size)\n",
    "#     cr.fill()\n",
    "\n",
    "#     ims.write_to_png(f\"graphics/coord/{i:02d}.png\")\n",
    "\n",
    "# anim_file = f'graphics/coord.mp4'\n",
    "\n",
    "# frames = []\n",
    "# filenames = glob.glob(f'graphics/coord/*.png')\n",
    "# filenames = sorted(filenames)\n",
    "# for i, filename in enumerate(filenames):\n",
    "#     frames.append(imageio.imread(filename))\n",
    "\n",
    "# imageio.mimsave(anim_file, frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9adbec-1fa9-4c80-b8b5-a7c73d2401fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shift_factor = 0\n",
    "scale_factor = 1\n",
    "\n",
    "def get_mgrid(sidelen, dim):\n",
    "    if dim == 4:\n",
    "        pixel_coords = np.stack(np.mgrid[:sidelen[0], :sidelen[1], :sidelen[2], :sidelen[3]], axis=-1)[None, ...].astype(np.float32)\n",
    "        for i in range(dim):\n",
    "            pixel_coords[..., i] = pixel_coords[..., i] / max(sidelen[i] - 1, 1)\n",
    "        pixel_coords = torch.from_numpy((pixel_coords - 0.5) * 2).view(-1, dim)\n",
    "        pixel_coords = pixel_coords + torch.Tensor([shift_factor, shift_factor, 0, 0])\n",
    "        pixel_coords = pixel_coords * torch.Tensor([scale_factor, scale_factor, 1, 1])\n",
    "        return pixel_coords.view((sidelen[0] * sidelen[1], sidelen[2], sidelen[3], dim))\n",
    "    raise NotImplementedError(f'Not implemented for dim={dim}')\n",
    "\n",
    "class LightFieldData:\n",
    "    def __init__(self, batch_size):\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def load_data_capture(self, data_folder):\n",
    "        u, v = 64, 64\n",
    "        h, w = 256, 256\n",
    "        c = 3\n",
    "        data = torch.zeros((u * v, h, w, c))\n",
    "        for ui in range(u):\n",
    "            for vi in range(v):\n",
    "                im = cv2.imread(f'{data_folder}/{vi:03d}-{ui:03d}.png')\n",
    "                im = cv2.resize(im, (h, w))\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                im = torch.from_numpy(((im * 2.0 / 255.0) - 1.0).astype(np.float32))\n",
    "                data[ui*u+vi] = im\n",
    "        \n",
    "        self.mgrid = get_mgrid((u, v, h, w), dim=4)\n",
    "        self.data = data\n",
    "        self.indices = np.arange(len(self.data))\n",
    "        self.cursor = len(self.indices)\n",
    "        self.height = h\n",
    "        self.width = w\n",
    "        \n",
    "        print(f\"Data:{self.data.shape}, Type:{self.data.dtype}, Range:{(self.data.min(), self.data.max())}\")\n",
    "        print(f\"Mesh Grid:{self.mgrid.shape}, Type:{self.mgrid.dtype}, Range:{(self.mgrid.min(), self.mgrid.max())}\")\n",
    "        \n",
    "    def shuffle(self):\n",
    "        self.indices = np.random.permutation(self.indices)\n",
    "        self.cursor = 0\n",
    "    \n",
    "    def next_batch(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if self.cursor + batch_size > len(self.indices):\n",
    "            self.shuffle()\n",
    "        batch_indices = self.indices[self.cursor:self.cursor + batch_size]\n",
    "        self.cursor += batch_size\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_coord = self.mgrid[batch_indices]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "    \n",
    "    def pixel_batch(self, batch_size):\n",
    "        data_shape = self.data.view(-1, 3).shape\n",
    "        pixel_ix = np.random.choice(data_shape[0], batch_size)\n",
    "        batch_data = self.data.view(-1, 3)[pixel_ix]\n",
    "        batch_coord = self.mgrid.view(-1, 4)[pixel_ix]\n",
    "        return batch_data.to(self.device), batch_coord.to(self.device)\n",
    "\n",
    "    def tensor_to_plt(self, in_tensor):\n",
    "        plt.imshow(in_tensor[...,0:3].detach().cpu().clamp(-1,1) * 0.5 + 0.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a35fe-b81c-41eb-bc02-312221a01cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_data = LightFieldData(batch_size=8)\n",
    "lf_data.load_data_capture('datasets/Ship-360')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d925fd-3238-48a5-a551-b9dcf183bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "W_0 = 30\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_hidden_layers, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(nn.Sequential(nn.Linear(in_features, hidden_features), Sine()))\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.net.append(nn.Sequential(nn.Linear(hidden_features, hidden_features), Sine()))\n",
    "        self.net.append(nn.Sequential(nn.Linear(hidden_features, out_features)))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.net.apply(sine_init)\n",
    "        self.net[0].apply(first_layer_sine_init)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "\n",
    "def sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-np.sqrt(6 / num_input) / W_0, np.sqrt(6 / num_input) / W_0)\n",
    "\n",
    "def first_layer_sine_init(m):\n",
    "    with torch.no_grad():\n",
    "        if hasattr(m, 'weight'):\n",
    "            num_input = m.weight.size(-1)\n",
    "            m.weight.uniform_(-1 / num_input, 1 / num_input)\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def __init(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(W_0 * input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        self.net = FCBlock(in_features, out_features, num_hidden_layers, hidden_features)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.net(inputs)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "layers = 3\n",
    "features = 1024\n",
    "model = Siren(in_features=4, out_features=3, hidden_features=features, num_hidden_layers=layers)\n",
    "\n",
    "model_str = f\"ship360-{layers}-{features}-{W_0}\"\n",
    "model.load_state_dict(torch.load(f\"outputs/{model_str}.pth\"))\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e6019-35b9-4ccc-af34-c3ca8e706104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "def to_uint8(im):\n",
    "    return ((im.detach().cpu().clamp(-1,1).numpy() * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "\n",
    "vid_folder = f'graphics/{model_str}'\n",
    "if not os.path.exists(vid_folder):\n",
    "    os.makedirs(vid_folder)\n",
    "    \n",
    "files = glob.glob(f'{vid_folder}/*.png')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "resolution = 120\n",
    "for i in range(resolution):\n",
    "    u = (i-resolution/2) / (resolution/2)\n",
    "    x = math.sin(math.pi * u)\n",
    "    z = math.cos(math.pi * u)\n",
    "    novel_coords = torch.Tensor([x, z]) * scale_factor\n",
    "    \n",
    "    im_coord = lf_data.mgrid[0].clone()\n",
    "    im_coord[:,:,:2] = novel_coords\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im_coord = im_coord.to(device)\n",
    "        model_out = model(im_coord)\n",
    "        model_out = to_uint8(model_out)\n",
    "        cv2.imwrite(f\"{vid_folder}/{i:03d}.png\", cv2.cvtColor(model_out, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "anim_file = f'{vid_folder}.mp4'\n",
    "\n",
    "frames = []\n",
    "filenames = glob.glob(f'{vid_folder}/*.png')\n",
    "filenames = sorted(filenames)\n",
    "for i, filename in enumerate(filenames):\n",
    "    frames.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave(anim_file, frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108b991-7c3c-4bee-bbfe-583abbebc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "cols = 4\n",
    "\n",
    "batch_data, _ = lf_data.next_batch(rows*cols)\n",
    "for i in range(len(batch_data[:2])):\n",
    "    lf_data.tensor_to_plt(batch_data[i])\n",
    "\n",
    "all_canvas = None\n",
    "for i in range(rows):\n",
    "    row_canvas = None\n",
    "    for j in range(cols):\n",
    "        gt_frame = to_uint8(batch_data[i*cols+j])\n",
    "        if j < cols-1:\n",
    "            gt_frame = np.hstack((gt_frame, np.zeros((gt_frame.shape[0], 16, 3), dtype=np.uint8)))\n",
    "        if row_canvas is None:\n",
    "            row_canvas = gt_frame\n",
    "        else:\n",
    "            row_canvas = np.hstack((row_canvas, gt_frame))\n",
    "    if i < rows-1:\n",
    "        row_canvas = np.vstack((row_canvas, np.zeros((16, row_canvas.shape[1], 3), dtype=np.uint8)))\n",
    "    if all_canvas is None:\n",
    "        all_canvas = row_canvas\n",
    "    else:\n",
    "        all_canvas = np.vstack((all_canvas, row_canvas))\n",
    "\n",
    "imageio.imwrite(f'graphics/views.png', all_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861eab1-ae6c-4f14-a2a0-40f65fc01a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
